# MÃ³dulo 6.2: IntroducciÃ³n a Pandas

> [!quote] "Los datos son el nuevo petrÃ³leo, pero Pandas es la refinerÃ­a que los transforma en conocimiento valioso." - Carlos CedeÃ±o ðŸ›¢ï¸â†’ðŸ’Ž

```mermaid
graph TB
    A[ðŸ¼ Pandas] --> B[ðŸ“Š Series]
    A --> C[ðŸ“‹ DataFrame]
    A --> D[ðŸ“ I/O Operations]
    
    B --> E[ðŸ”¢ Array 1D]
    B --> F[ðŸ·ï¸ Ãndices]
    
    C --> G[ðŸ¢ Tabla 2D]
    C --> H[ðŸ“ˆ AnÃ¡lisis]
    
    D --> I[ðŸ“„ CSV]
    D --> J[ðŸ“Š Excel]
    D --> K[ðŸŒ JSON]
    
    style A fill:#ff9999,stroke:#333,stroke-width:3px
    style B fill:#99ccff,stroke:#333,stroke-width:2px
    style C fill:#99ff99,stroke:#333,stroke-width:2px
    style D fill:#ffcc99,stroke:#333,stroke-width:2px
```

## ðŸ“‹ Objetivos del MÃ³dulo

> [!success]- **ðŸŽ¯ Metas de Aprendizaje** Al finalizar este mÃ³dulo, serÃ¡s capaz de:
> 
> - ðŸ” **Comprender** quÃ© es Pandas y su importancia en el ecosistema de datos
> - ðŸ§± **Dominar** las estructuras fundamentales: Series y DataFrame
> - ðŸ“‚ **Manipular** archivos en mÃºltiples formatos (CSV, Excel, JSON)
> - ðŸ•µï¸ **Explorar** datasets para entender su estructura y contenido
> - ðŸŽ¯ **Seleccionar** datos usando tÃ©cnicas avanzadas de indexaciÃ³n
> - ðŸ” **Filtrar** informaciÃ³n con condiciones complejas

## ðŸ¼ 1. Â¿QuÃ© es Pandas?

> [!info]- **ðŸŒŸ El Poder de Pandas** **Pandas** (Panel Data) es una biblioteca de cÃ³digo abierto que revoluciona el anÃ¡lisis de datos en Python. Inspirada en R y Excel, combina la simplicidad con el poder computacional de Python.
> 
> ### ðŸš€ Â¿Por quÃ© Pandas es tan popular?
> 
> |CaracterÃ­stica|DescripciÃ³n|Emoji|
> |---|---|---|
> |**Intuitivo**|Sintaxis clara que refleja el pensamiento analÃ­tico|ðŸ§ |
> |**Eficiente**|Optimizado para grandes volÃºmenes de datos|âš¡|
> |**VersÃ¡til**|Compatible con 20+ formatos de archivo|ðŸ”„|
> |**Integrado**|Funciona perfectamente con NumPy, Matplotlib|ðŸ”—|
> |**Potente**|Operaciones complejas en pocas lÃ­neas|ðŸ’ª|

> [!tip]- **âš™ï¸ InstalaciÃ³n y ConfiguraciÃ³n**
> 
> ```python
> # ðŸ“¦ InstalaciÃ³n (ejecutar una sola vez)
> pip install pandas openpyxl xlrd
> 
> # ðŸ“š ImportaciÃ³n estÃ¡ndar
> import pandas as pd
> import numpy as np
> 
> # ðŸ”§ Configuraciones Ãºtiles
> pd.set_option('display.max_columns', None)    # Mostrar todas las columnas
> pd.set_option('display.width', None)          # Ancho automÃ¡tico
> pd.set_option('display.max_colwidth', 100)    # Ancho mÃ¡ximo por columna
> 
> # âœ… Verificar versiÃ³n
> print(f"VersiÃ³n de Pandas: {pd.__version__}")
> ```

## ðŸ“Š 2. Estructuras de Datos Fundamentales

```mermaid
graph LR
    A[ðŸ—ï¸ Estructuras de Datos] --> B[ðŸ“ˆ Series]
    A --> C[ðŸ“‹ DataFrame]
    
    B --> D[ðŸ“Š Array 1D]
    B --> E[ðŸ·ï¸ Ãndices personalizados]
    B --> F[ðŸ”¢ HomogÃ©neo]
    
    C --> G[ðŸ“‹ Tabla 2D]
    C --> H[ðŸ“Š MÃºltiples Series]
    C --> I[ðŸ” AnÃ¡lisis completo]
    
    style B fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    style C fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
```

> [!success]- **ðŸ“ˆ Series: La Columna Inteligente** Una **Series** es un array unidimensional con etiquetas (Ã­ndices). Es como una columna de Excel con superpoderes.
> 
> ### ðŸ”‘ CaracterÃ­sticas Clave:
> 
> - **ðŸŽ¯ HomogÃ©nea**: Todos los elementos del mismo tipo
> - **ðŸ·ï¸ Indexada**: Cada valor tiene una etiqueta Ãºnica
> - **ðŸ”€ Flexible**: Ãndice numÃ©rico, texto, fechas, etc.
> 
> ```python
> import pandas as pd
> 
> # ðŸŽ Crear Series desde lista
> frutas = pd.Series(['Manzana', 'Banana', 'Cereza', 'Durazno'])
> print("Series bÃ¡sica:")
> print(frutas)
> 
> # ðŸ’° Series con Ã­ndice personalizado
> precios = pd.Series([1.5, 0.8, 3.2, 2.1], 
>                   index=['Manzana', 'Banana', 'Cereza', 'Durazno'],
>                   name='Precios_USD')
> print("\nSeries con Ã­ndice personalizado:")
> print(precios)
> ```
> 
> ### ðŸ› ï¸ Operaciones BÃ¡sicas:
> 
> ```python
> # ðŸŽ¯ Acceso por Ã­ndice
> print(f"Precio de Manzana: ${precios['Manzana']}")
> print(f"Primer elemento: ${precios.iloc[0]}")
> 
> # ðŸ§® Operaciones matemÃ¡ticas
> precios_con_iva = precios * 1.12  # 12% de IVA
> print(f"Precios con IVA:\n{precios_con_iva}")
> 
> # ðŸ” Filtrado
> frutas_caras = precios[precios > 2.0]
> print(f"Frutas caras (>$2):\n{frutas_caras}")
> 
> # ðŸ“Š EstadÃ­sticas
> print(f"Precio promedio: ${precios.mean():.2f}")
> print(f"Precio mÃ¡ximo: ${precios.max():.2f}")
> ```

> [!tip]- **ðŸ“‹ DataFrame: La Tabla de Datos Definitiva** El **DataFrame** es la estructura estrella de Pandas. Es una tabla bidimensional donde cada columna es una Series.
> 
> ### ðŸ” AnalogÃ­as para Entender DataFrame:
> 
> |AnalogÃ­a|DescripciÃ³n|Emoji|
> |---|---|---|
> |**Hoja de Excel**|Filas y columnas organizadas|ðŸ“Š|
> |**Base de datos**|Tabla con registros y campos|ðŸ—ƒï¸|
> |**Diccionario de listas**|Claves como columnas, valores como datos|ðŸ“š|
> 
> ```python
> # ðŸ‘¥ Crear DataFrame desde diccionario
> datos_estudiantes = {
>    'Nombre': ['Ana GarcÃ­a', 'Luis PÃ©rez', 'Marta LÃ³pez', 'Juan Silva'],
>    'Edad': [20, 22, 19, 21],
>    'Ciudad': ['Quito', 'Guayaquil', 'Cuenca', 'Quito'],
>    'Carrera': ['IngenierÃ­a', 'Medicina', 'Derecho', 'IngenierÃ­a'],
>    'Promedio': [9.2, 8.7, 9.5, 8.9]
> }
> 
> df_estudiantes = pd.DataFrame(datos_estudiantes)
> print("DataFrame de estudiantes:")
> print(df_estudiantes)
> ```
> 
> ### ðŸ“ Propiedades Esenciales:
> 
> ```python
> # ðŸ“ InformaciÃ³n estructural
> print(f"Dimensiones: {df_estudiantes.shape}")  # (filas, columnas)
> print(f"Columnas: {list(df_estudiantes.columns)}")
> print(f"Ãndice: {list(df_estudiantes.index)}")
> print(f"Tipos de datos:\n{df_estudiantes.dtypes}")
> 
> # â„¹ï¸ InformaciÃ³n general
> df_estudiantes.info()
> 
> # ðŸ“ˆ EstadÃ­sticas descriptivas
> print(df_estudiantes.describe())
> ```

> [!example]- **ðŸŽ¯ MÃºltiples Formas de Crear DataFrames**
> 
> ```python
> # 1ï¸âƒ£ Desde diccionario de listas
> ventas_dict = {
>    'Producto': ['Laptop', 'Mouse', 'Teclado', 'Monitor'],
>    'Cantidad': [5, 20, 15, 8],
>    'Precio_Unitario': [800, 25, 45, 300]
> }
> df_ventas = pd.DataFrame(ventas_dict)
> 
> # 2ï¸âƒ£ Desde lista de diccionarios
> empleados_list = [
>    {'nombre': 'Carlos', 'departamento': 'IT', 'salario': 3000},
>    {'nombre': 'MarÃ­a', 'departamento': 'Ventas', 'salario': 2800},
>    {'nombre': 'JosÃ©', 'departamento': 'IT', 'salario': 3200}
> ]
> df_empleados = pd.DataFrame(empleados_list)
> 
> # 3ï¸âƒ£ Desde array NumPy
> import numpy as np
> datos_random = np.random.randn(4, 3)
> df_random = pd.DataFrame(datos_random, 
>                        columns=['A', 'B', 'C'],
>                        index=['Fila1', 'Fila2', 'Fila3', 'Fila4'])
> 
> # 4ï¸âƒ£ DataFrame vacÃ­o
> df_vacio = pd.DataFrame(columns=['Nombre', 'Edad', 'Ciudad'])
> ```

## ðŸ“ 3. Lectura y Escritura de Archivos

```mermaid
graph TB
    A[ðŸ“ Archivos] --> B[ðŸ“„ CSV]
    A --> C[ðŸ“Š Excel]
    A --> D[ðŸŒ JSON]
    A --> E[ðŸ”„ Otros]
    
    B --> F[pd.read_csv]
    B --> G[df.to_csv]
    
    C --> H[pd.read_excel]
    C --> I[df.to_excel]
    
    D --> J[pd.read_json]
    D --> K[df.to_json]
    
    E --> L[Parquet, SQL, HTML]
    
    style A fill:#fff3e0,stroke:#e65100,stroke-width:3px
    style B fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    style C fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    style D fill:#fce4ec,stroke:#c2185b,stroke-width:2px
```

> [!success]- **ðŸ“„ Lectura de Archivos CSV** Los archivos CSV son fundamentales en el anÃ¡lisis de datos. Pandas los maneja con elegancia.
> 
> ### ðŸ” Lectura BÃ¡sica:
> 
> ```python
> # ðŸ“‚ Lectura simple
> df = pd.read_csv('datos_ventas.csv')
> 
> # âš™ï¸ Lectura con parÃ¡metros
> df = pd.read_csv('datos_ventas.csv',
>                 sep=',',           # Separador
>                 encoding='utf-8',  # CodificaciÃ³n
>                 index_col=0,       # Columna como Ã­ndice
>                 header=0)          # Fila de encabezados
> 
> # ðŸ”§ Para archivos problemÃ¡ticos
> df = pd.read_csv('datos_sucios.csv',
>                 sep=';',                    # Separador ;
>                 decimal=',',                # Coma decimal
>                 thousands='.',              # Punto miles
>                 encoding='latin-1',         # CodificaciÃ³n
>                 na_values=['', 'N/A', 'NULL'])  # Valores nulos
> ```
> 
> ### ðŸŽ¯ ParÃ¡metros Avanzados:
> 
> ```python
> # ðŸ“Š Leer columnas especÃ­ficas
> df_parcial = pd.read_csv('datos_grandes.csv', 
>                        usecols=['Nombre', 'Edad', 'Salario'])
> 
> # ðŸ“ Leer filas limitadas
> df_muestra = pd.read_csv('datos_grandes.csv', 
>                        nrows=1000,      # Primeras 1000 filas
>                        skiprows=5)      # Saltar 5 filas
> 
> # ðŸ·ï¸ Especificar tipos
> tipos_datos = {
>    'ID': 'int64',
>    'Nombre': 'string',
>    'Activo': 'boolean'
> }
> df_tipado = pd.read_csv('empleados.csv', dtype=tipos_datos)
> ```

> [!tip]- **ðŸ“Š Lectura de Archivos Excel** Excel sigue siendo omnipresente en el mundo empresarial.
> 
> ```python
> # ðŸ“‹ InstalaciÃ³n necesaria
> # pip install openpyxl xlrd
> 
> # ðŸ“‚ Lectura bÃ¡sica
> df = pd.read_excel('reporte_mensual.xlsx')
> 
> # ðŸ“‘ Hoja especÃ­fica
> df_ventas = pd.read_excel('reporte_anual.xlsx', sheet_name='Ventas_2024')
> 
> # ðŸ“š MÃºltiples hojas
> diccionario_hojas = pd.read_excel('reporte_anual.xlsx', sheet_name=None)
> df_ventas = diccionario_hojas['Ventas_2024']
> df_gastos = diccionario_hojas['Gastos_2024']
> 
> # âš™ï¸ ParÃ¡metros avanzados
> df = pd.read_excel('reporte_complejo.xlsx',
>                  sheet_name='Datos',
>                  header=2,           # Encabezados en fila 3
>                  skiprows=[0, 1],    # Saltar filas 1 y 2
>                  usecols='A:E',      # Columnas A-E
>                  nrows=100)          # 100 filas
> ```

> [!example]- **ðŸŒ JSON y Otros Formatos**
> 
> ```python
> # ðŸŒ JSON - ComÃºn con APIs
> df_usuarios = pd.read_json('usuarios_api.json')
> 
> # ðŸ”„ JSON complejo
> df_normalizado = pd.json_normalize(data, record_path='usuarios')
> 
> # ðŸ“¦ Otros formatos Ãºtiles
> df_pickle = pd.read_pickle('datos_procesados.pkl')     # Nativo Pandas
> df_parquet = pd.read_parquet('datos_grandes.parquet')  # Eficiente
> df_html = pd.read_html('https://example.com/tabla.html')[0]  # Tablas web
> 
> # ðŸ—„ï¸ Desde base de datos
> import sqlite3
> conn = sqlite3.connect('mi_base.db')
> df_sql = pd.read_sql_query('SELECT * FROM ventas WHERE aÃ±o = 2024', conn)
> ```

> [!warning]- **ðŸ’¾ Escritura de Archivos**
> 
> ### ðŸ“„ Guardar en CSV:
> 
> ```python
> # ðŸ’¾ Guardado bÃ¡sico
> df_estudiantes.to_csv('estudiantes_procesados.csv', index=False)
> 
> # âš™ï¸ Con parÃ¡metros especÃ­ficos
> df_estudiantes.to_csv('estudiantes_especial.csv',
>                     index=False,           # Sin Ã­ndice
>                     sep=';',               # Punto y coma
>                     encoding='utf-8',      # UTF-8
>                     decimal=',',           # Coma decimal
>                     float_format='%.2f')   # 2 decimales
> ```
> 
> ### ðŸ“Š Guardar en Excel:
> 
> ```python
> # ðŸ“‹ Excel simple
> df_estudiantes.to_excel('estudiantes.xlsx', index=False)
> 
> # ðŸ“š Excel mÃºltiples hojas
> with pd.ExcelWriter('reporte_completo.xlsx') as writer:
>    df_estudiantes.to_excel(writer, sheet_name='Estudiantes', index=False)
>    df_ventas.to_excel(writer, sheet_name='Ventas', index=False)
>    df_empleados.to_excel(writer, sheet_name='Empleados', index=False)
> ```

## ðŸ” 4. ExploraciÃ³n de DataFrames

> [!info]- **ðŸ•µï¸ Comandos de ExploraciÃ³n Esenciales**
> 
> ```python
> # ðŸ—ï¸ Crear dataset de ejemplo
> np.random.seed(42)
> datos_empleados = {
>    'ID': range(1, 101),
>    'Nombre': [f'Empleado_{i}' for i in range(1, 101)],
>    'Departamento': np.random.choice(['IT', 'Ventas', 'Marketing', 'RRHH'], 100),
>    'Salario': np.random.normal(50000, 15000, 100).round(2),
>    'AÃ±os_Experiencia': np.random.randint(0, 20, 100),
>    'Activo': np.random.choice([True, False], 100, p=[0.9, 0.1])
> }
> df_empresa = pd.DataFrame(datos_empleados)
> 
> # ðŸ“ InformaciÃ³n estructural
> print("=== INFORMACIÃ“N ESTRUCTURAL ===")
> print(f"Dimensiones: {df_empresa.shape}")
> print(f"Total de celdas: {df_empresa.size}")
> print(f"Memoria usada: {df_empresa.memory_usage(deep=True).sum() / 1024:.1f} KB")
> ```
> 
> ### ðŸ‘€ Vista RÃ¡pida:
> 
> ```python
> # ðŸ” Primeras filas
> print("Primeras 3 filas:")
> print(df_empresa.head(3))
> 
> # ðŸ”š Ãšltimas filas
> print("Ãšltimas 3 filas:")
> print(df_empresa.tail(3))
> 
> # ðŸŽ² Muestra aleatoria
> print("Muestra aleatoria:")
> print(df_empresa.sample(5))
> 
> # â„¹ï¸ InformaciÃ³n detallada
> df_empresa.info()
> ```

> [!tip]- **ðŸ“ˆ AnÃ¡lisis EstadÃ­stico RÃ¡pido**
> 
> ```python
> # ðŸ“Š EstadÃ­sticas descriptivas
> print("=== ESTADÃSTICAS DESCRIPTIVAS ===")
> print(df_empresa.describe())
> 
> # ðŸ”¤ Incluyendo categÃ³ricas
> print("EstadÃ­sticas completas:")
> print(df_empresa.describe(include='all'))
> 
> # ðŸ“‹ AnÃ¡lisis categÃ³rico
> print("=== ANÃLISIS CATEGÃ“RICO ===")
> for col in ['Departamento', 'Activo']:
>    print(f"\nDistribuciÃ³n de {col}:")
>    conteos = df_empresa[col].value_counts()
>    porcentajes = df_empresa[col].value_counts(normalize=True) * 100
>    
>    for valor, conteo, pct in zip(conteos.index, conteos.values, porcentajes.values):
>        print(f"  {valor}: {conteo} ({pct:.1f}%)")
> ```

> [!success]- **âš ï¸ DiagnÃ³stico de Calidad de Datos**
> 
> ```python
> def diagnostico_completo(df):
>    """
>    ðŸ” FunciÃ³n para diagnÃ³stico completo de un DataFrame
>    """
>    print("ðŸ” DIAGNÃ“STICO COMPLETO DEL DATASET")
>    print("=" * 50)
>    
>    # ðŸ“Š InformaciÃ³n bÃ¡sica
>    print(f"ðŸ“Š Dimensiones: {df.shape[0]:,} filas Ã— {df.shape[1]} columnas")
>    print(f"ðŸ’¾ Memoria: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
>    
>    # ðŸ•³ï¸ Valores nulos
>    nulos = df.isnull().sum()
>    if nulos.sum() > 0:
>        print(f"\nâš ï¸  VALORES NULOS DETECTADOS:")
>        for col, count in nulos[nulos > 0].items():
>            pct = (count / len(df)) * 100
>            print(f"   {col}: {count:,} ({pct:.1f}%)")
>    else:
>        print(f"\nâœ… Sin valores nulos")
>    
>    # ðŸ”„ Duplicados
>    duplicados = df.duplicated().sum()
>    if duplicados > 0:
>        print(f"\nâš ï¸  DUPLICADOS: {duplicados:,} filas ({(duplicados/len(df)*100):.1f}%)")
>    else:
>        print(f"\nâœ… Sin duplicados")
>    
>    return df.shape, nulos.sum(), duplicados
> 
> # ðŸš€ Aplicar diagnÃ³stico
> diagnostico_completo(df_empresa)
> ```

## ðŸŽ¯ 5. SelecciÃ³n de Datos

```mermaid
graph TB
    A[ðŸŽ¯ SelecciÃ³n de Datos] --> B[ðŸ“Š Columnas]
    A --> C[ðŸ“‹ Filas]
    A --> D[ðŸ” Filtros]
    
    B --> E[ðŸ”¤ Por nombre]
    B --> F[ðŸ“ MÃºltiples]
    B --> G[ðŸ” Por tipo]
    
    C --> H[.loc - etiquetas]
    C --> I[.iloc - posiciÃ³n]
    
    D --> J[â“ Condicionales]
    D --> K[ðŸ”— Combinados]
    
    style A fill:#e8f5e8,stroke:#388e3c,stroke-width:3px
    style H fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style I fill:#fce4ec,stroke:#c2185b,stroke-width:2px
```

> [!success]- **ðŸ“Š SelecciÃ³n de Columnas**
> 
> ```python
> # 1ï¸âƒ£ Una sola columna (devuelve Series)
> nombres = df_empresa['Nombre']
> print(f"Tipo: {type(nombres)}")
> 
> # 2ï¸âƒ£ MÃºltiples columnas (devuelve DataFrame)
> info_basica = df_empresa[['Nombre', 'Departamento', 'Salario']]
> print(f"Columnas seleccionadas: {list(info_basica.columns)}")
> 
> # 3ï¸âƒ£ Por tipo de datos
> columnas_numericas = df_empresa.select_dtypes(include=[np.number]).columns
> df_numerico = df_empresa[columnas_numericas]
> 
> # 4ï¸âƒ£ SelecciÃ³n dinÃ¡mica
> columnas_interes = ['Nombre', 'Salario', 'AÃ±os_Experiencia']
> columnas_disponibles = [col for col in columnas_interes if col in df_empresa.columns]
> df_filtrado = df_empresa[columnas_disponibles]
> ```

> [!tip]- **ðŸŽ¯ SelecciÃ³n de Filas: loc vs iloc**
> 
> ### ðŸ”‘ Diferencia Clave:
> 
> |MÃ©todo|DescripciÃ³n|Tipo|Rango|
> |---|---|---|---|
> |**`.loc`**|Por etiquetas/nombres|ðŸ·ï¸ Labels|Inclusivo|
> |**`.iloc`**|Por posiciÃ³n numÃ©rica|ðŸ”¢ Position|Exclusivo|
> 
> ```python
> # ðŸ—ï¸ Crear ejemplo con Ã­ndice personalizado
> df_ejemplo = df_empresa.set_index('ID').head(10)
> 
> # === ðŸ·ï¸ USANDO .loc (etiquetas) ===
> print("=== EJEMPLOS CON .loc ===")
> 
> # Por etiqueta de Ã­ndice
> empleado_5 = df_ejemplo.loc[5]
> print(f"Empleado ID 5: {empleado_5['Nombre']}")
> 
> # Rango INCLUSIVO
> empleados_3_a_7 = df_ejemplo.loc[3:7]  # Incluye 3,4,5,6,7
> print(f"IDs 3-7: {len(empleados_3_a_7)} empleados")
> 
> # Filas y columnas especÃ­ficas
> datos_especificos = df_ejemplo.loc[2:5, ['Nombre', 'Salario']]
> 
> # === ðŸ”¢ USANDO .iloc (posiciÃ³n) ===
> print("=== EJEMPLOS CON .iloc ===")
> 
> # Por posiciÃ³n
> primera_fila = df_ejemplo.iloc[0]  # Primera fila
> print(f"Primera fila: ID {primera_fila.name}")
> 
> # Rango EXCLUSIVO
> primeras_3 = df_ejemplo.iloc[0:3]  # Posiciones 0,1,2
> print(f"Primeras 3 filas: {len(primeras_3)} empleados")
> 
> # Ãšltima fila
> ultima_fila = df_ejemplo.iloc[-1]
> print(f"Ãšltima fila: ID {ultima_fila.name}")
> ```

## ðŸ” 6. Filtrado Condicional

> [!example]- **ðŸ” Filtros BÃ¡sicos**
> 
> ```python
> # ðŸ’° Filtros simples
> salarios_altos = df_empresa[df_empresa['Salario'] > 60000]
> print(f"Empleados con salario > $60,000: {len(salarios_altos)}")
> 
> # ðŸ¢ Filtros con texto
> departamento_it = df_empresa[df_empresa['Departamento'] == 'IT']
> print(f"Empleados en IT: {len(departamento_it)}")
> 
> # âœ… Filtros booleanos
> empleados_activos = df_empresa[df_empresa['Activo'] == True]
> print(f"Empleados activos: {len(empleados_activos)}")
> 
> # ðŸŒ± Empleados junior
> juniors = df_empresa.loc[df_empresa['AÃ±os_Experiencia'] < 5]
> print(f"Empleados junior (< 5 aÃ±os): {len(juniors)}")
> ```

> [!tip]- **ðŸ”— Filtros Combinados: Y, O, No**
> 
> ### ðŸ§® Operadores LÃ³gicos:
> 
> |Operador|SÃ­mbolo|DescripciÃ³n|Emoji|
> |---|---|---|---|
> |**Y (AND)**|`&`|Ambas condiciones verdaderas|âœ…|
> |**O (OR)**|`\|`|Al menos una verdadera|ðŸ”„|
> |**NO (NOT)**|`~`|NegaciÃ³n|âŒ|
> 
> ```python
> # âœ… Operador Y (&)
> it_seniors = df_empresa[
>    (df_empresa['Departamento'] == 'IT') & 
>    (df_empresa['AÃ±os_Experiencia'] >= 10)
> ]
> print(f"IT Seniors: {len(it_seniors)}")
> 
> # ðŸ”„ Operador O (|)
> altos_o_expertos = df_empresa[
>    (df_empresa['Salario'] > 70000) | 
>    (df_empresa['AÃ±os_Experiencia'] > 15)
> ]
> print(f"Salario alto O mucha experiencia: {len(altos_o_expertos)}")
> 
> # âŒ Operador NO (~)
> no_it = df_empresa[~(df_empresa['Departamento'] == 'IT')]
> print(f"No IT: {len(no_it)}")
> 
> # ðŸŽ¯ Filtro complejo
> perfil_especifico = df_empresa[
>    (df_empresa['Salario'].between(40000, 60000)) &
>    (df_empresa['AÃ±os_Experiencia'] >= 3) &
>    (df_empresa['Activo'] == True) &
>    (df_empresa['Departamento'].isin(['Ventas', 'Marketing']))
> ]
> print(f"Perfil especÃ­fico: {len(perfil_especifico)}")
> ```

> [!success]- **ðŸŽ¯ MÃ©todos Avanzados de Filtrado**
> 
> ```python
> # ðŸ“‹ Usando .isin() para mÃºltiples valores
> departamentos_objetivo = ['IT', 'Ventas']
> empleados_objetivo = df_empresa[
>    df_empresa['Departamento'].isin(departamentos_objetivo)
> ]
> print(f"IT y Ventas: {len(empleados_objetivo)}")
> 
> # ðŸ”¢ IDs especÃ­ficos
> ids_interes = [1, 5, 10, 15, 20]
> empleados_especificos = df_empresa[
>    df_empresa['ID'].isin(ids_interes)
> ]
> 
> # ðŸ“Š Usando query() (alternativa elegante)
> resultado_query = df_empresa.query(
>    'Salario > 50000 and Departamento == "IT" and Activo == True'
> )
> print(f"Query result: {len(resultado_query)}")
> 
> # ðŸ” Filtros con strings
> nombres_con_a = df_empresa[df_empresa['Nombre'].str.contains('a', case=False)]
> print(f"Nombres con 'a': {len(nombres_con_a)}")
> ```

## ðŸ§  TÃ©cnica de Estudio: MÃ©todo PANDAS

> [!note]- **ðŸŽ“ Mnemotecnia PANDAS** Para recordar los pasos del anÃ¡lisis de datos con Pandas:
> 
> **P** - **Preparar**: Importar pandas y configurar el entorno **A** - **Abrir**: Leer los archivos de datos (CSV, Excel, JSON) **N** - **Navegar**: Explorar el DataFrame (head, info, describe) **D** - **Detectar**: Identificar problemas (nulos, duplicados, tipos) **A** - **Analizar**: Aplicar filtros y selecciones **S** - **Salvar**: Guardar los resultados procesados
> 
> ### ðŸ”„ MÃ©todo de Repaso Espaciado:
> 
> - **DÃ­a 1**: Conceptos bÃ¡sicos (Series, DataFrame)
> - **DÃ­a 3**: Lectura de archivos y exploraciÃ³n
> - **DÃ­a 7**: SelecciÃ³n y filtrado avanzado
> - **DÃ­a 14**: Proyecto prÃ¡ctico completo
> - **DÃ­a 30**: RevisiÃ³n general y casos complejos

## ðŸ› ï¸ Ejercicios PrÃ¡cticos

> [!example]- **ðŸš€ Ejercicio 1: AnÃ¡lisis de Ventas**
> 
> ```python
> # ðŸ“Š Crear dataset de ventas
> import pandas as pd
> import numpy as np
> 
> ventas_data = {
>    'fecha': pd.date_range('2024-01-01', periods=100, freq='D'),
>    'producto': np.random.choice(['Laptop', 'Mouse', 'Teclado', 'Monitor'], 100),
>    'vendedor': np.random.choice(['Ana', 'Luis', 'MarÃ­a', 'Carlos'], 100),
>    'cantidad': np.random.randint(1, 10, 100),
>    'precio_unitario': np.random.choice([25, 45, 800, 300], 100),
>    'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], 100)
> }
> 
> df_ventas = pd.DataFrame(ventas_data)
> df_ventas['total'] = df_ventas['cantidad'] * df_ventas['precio_unitario']
> 
> # âœ… Tareas:
> # 1. Explorar el dataset
> # 2. Encontrar las 5 ventas mÃ¡s altas
> # 3. Ventas por vendedor
> # 4. Productos mÃ¡s vendidos por regiÃ³n
> ```

> [!example]- **ðŸŽ¯ Ejercicio 2: AnÃ¡lisis Estudiantil**
> 
> ```python
> # ðŸŽ“ Dataset de estudiantes
> estudiantes_data = {
>    'nombre': [f'Estudiante_{i}' for i in range(1, 51)],
>    'edad': np.random.randint(18, 25, 50),
>    'carrera': np.random.choice(['IngenierÃ­a', 'Medicina', 'Derecho', 'EconomÃ­a'], 50),
>    'semestre': np.random.randint(1, 10, 50),
>    'promedio': np.random.normal(8.0, 1.5, 50).round(2),
>    'ciudad': np.random.choice(['Quito', 'Guayaquil', 'Cuenca', 'Ambato'], 50),
>    'beca': np.random.choice([True, False], 50, p=[0.3, 0.7])
> }
> 
> df_estudiantes = pd.DataFrame(estudiantes_data)
> 
> # âœ… Tareas:
> # 1. Estudiantes con beca y promedio > 8.5
> # 2. DistribuciÃ³n por carrera y ciudad
> # 3. Estudiantes de Ãºltimo semestre por carrera
> # 4. AnÃ¡lisis estadÃ­stico por carrera
> ```

## ðŸ”— Referencias y Conexiones

> [!quote]- **ðŸ“š Referencias a Otras Notas**
> 
> - [[MÃ³dulo 6.1 IntroducciÃ³n a NumPy]] - Base matemÃ¡tica para Pandas
> - [[MÃ³dulo 5.1 Diccionarios]] - Estructura similar a DataFrames
> - [[MÃ³dulo 2.3 Listas y Tuplas en Python]] - Fundamentos de estructuras de datos
> - [[Funciones Built-in]] - Funciones que complementan Pandas
> - [[Manejo de Errores con try, except, finally]] - Para lectura robusta de archivos

> [!info]- **ðŸŽ¯ Notas Recomendadas**
> 
> ### ðŸ“‹ Prerrequisitos:
> 
> - Conocimiento bÃ¡sico de Python
> - Manejo de listas y diccionarios
> - Conceptos de programaciÃ³n orientada a objetos
> 
> ### ðŸš€ PrÃ³ximos Pasos:
> 
> - VisualizaciÃ³n de datos con Matplotlib
> - AnÃ¡lisis estadÃ­stico avanzado
> - Machine Learning con scikit-learn
> - ManipulaciÃ³n avanzada de datos

## ðŸ“Š Comparativa: Pandas vs Otras Herramientas

> [!tip]- **âš–ï¸ Pandas vs Competidores**
> 
> |Herramienta|Fortalezas|Debilidades|Caso de Uso|
> |---|---|---|---|
> |**ðŸ¼ Pandas**|Versatilidad, ecosistema Python|Memoria limitada|AnÃ¡lisis general|
> |**ðŸ“Š Excel**|Interfaz visual, familiar|Escalabilidad limitada|AnÃ¡lisis bÃ¡sico|
> |**ðŸ” SQL**|Grandes datos, velocidad|Curva aprendizaje|Bases de datos|
> |**ðŸ“ˆ R**|EstadÃ­stica avanzada|Sintaxis compleja|InvestigaciÃ³n|
> |**âš¡ Spark**|Big Data, distribuciÃ³n|Complejidad setup|Datos masivos|

## ðŸŽ¨ Proyecto Final: Dashboard de Datos

> [!success]- **ðŸ† Proyecto Integrador**
> 
> ```python
> # ðŸŽ¯ Crear un anÃ¡lisis completo de datos empresariales
> import pandas as pd
> import numpy as np
> from datetime import datetime, timedelta
> 
> class AnalizadorEmpresarial:
>    def __init__(self):
>        self.df = None
>        
>    def generar_datos_muestra(self, n_empleados=200):
>        """ðŸ­ Generar dataset empresarial realista"""
>        np.random.seed(42)
>        
>        datos = {
>            'id_empleado': range(1, n_empleados + 1),
>            'nombre': [f'Empleado_{i}' for i in range(1, n_empleados + 1)],
>            'departamento': np.random.choice(
>                ['IT', 'Ventas', 'Marketing', 'RRHH', 'Finanzas'], 
>                n_empleados, 
>                p=[0.3, 0.25, 0.15, 0.15, 0.15]
>            ),
>            'cargo': np.random.choice(
>                ['Junior', 'Senior', 'Lead', 'Manager'], 
>                n_empleados,
>                p=[0.4, 0.35, 0.15, 0.1]
>            ),
>            'salario': np.random.normal(50000, 20000, n_empleados).round(2),
>            'aÃ±os_experiencia': np.random.randint(0, 20, n_empleados),
>            'fecha_ingreso': [
>                datetime.now() - timedelta(days=np.random.randint(30, 3650))
>                for _ in range(n_empleados)
>            ],
>            'activo': np.random.choice([True, False], n_empleados, p=[0.95, 0.05]),
>            'satisfaccion': np.random.randint(1, 11, n_empleados),
>            'ciudad': np.random.choice(
>                ['Quito', 'Guayaquil', 'Cuenca', 'Ambato'], 
>                n_empleados
>            )
>        }
>        
>        self.df = pd.DataFrame(datos)
>        return self.df
>    
>    def diagnostico_completo(self):
>        """ðŸ” AnÃ¡lisis completo del dataset"""
>        print("ðŸ¢ REPORTE EMPRESARIAL COMPLETO")
>        print("=" * 60)
>        
>        # InformaciÃ³n bÃ¡sica
>        print(f"ðŸ‘¥ Total empleados: {len(self.df):,}")
>        print(f"ðŸ¢ Departamentos: {self.df['departamento'].nunique()}")
>        print(f"ðŸŒ Ciudades: {self.df['ciudad'].nunique()}")
>        
>        # AnÃ¡lisis salarial
>        print(f"\nðŸ’° ANÃLISIS SALARIAL:")
>        print(f"Salario promedio: ${self.df['salario'].mean():,.2f}")
>        print(f"Salario mediano: ${self.df['salario'].median():,.2f}")
>        print(f"Rango salarial: ${self.df['salario'].min():,.2f} - ${self.df['salario'].max():,.2f}")
>        
>        # Por departamento
>        print(f"\nðŸ¢ POR DEPARTAMENTO:")
>        dept_stats = self.df.groupby('departamento').agg({
>            'salario': ['mean', 'count'],
>            'satisfaccion': 'mean'
>        }).round(2)
>        print(dept_stats)
>        
>        return dept_stats
>    
>    def empleados_destacados(self):
>        """ðŸŒŸ Identificar empleados destacados"""
>        # Criterios: Alta satisfacciÃ³n, buen salario, experiencia
>        destacados = self.df[
>            (self.df['satisfaccion'] >= 8) &
>            (self.df['aÃ±os_experiencia'] >= 5) &
>            (self.df['salario'] > self.df['salario'].quantile(0.75))
>        ].sort_values('satisfaccion', ascending=False)
>        
>        print(f"ðŸŒŸ EMPLEADOS DESTACADOS ({len(destacados)}):")
>        for _, emp in destacados.head(10).iterrows():
>            print(f"â€¢ {emp['nombre']} - {emp['departamento']} - "
>                  f"SatisfacciÃ³n: {emp['satisfaccion']}/10")
>        
>        return destacados
> 
> # ðŸš€ Usar el analizador
> analizador = AnalizadorEmpresarial()
> df_empresa = analizador.generar_datos_muestra(300)
> analizador.diagnostico_completo()
> analizador.empleados_destacados()
> ```

## ðŸŽ¯ Casos de Uso Reales

> [!example]- **ðŸŒŸ Aplicaciones en el Mundo Real**
> 
> ### ðŸª **Retail y E-commerce**
> 
> ```python
> # AnÃ¡lisis de comportamiento del cliente
> analisis_clientes = df_ventas.groupby('cliente_id').agg({
>    'total_compra': ['sum', 'mean', 'count'],
>    'fecha_compra': ['min', 'max']
> })
> ```
> 
> ### ðŸ¥ **Salud y Medicina**
> 
> ```python
> # AnÃ¡lisis de datos mÃ©dicos
> pacientes_riesgo = df_pacientes[
>    (df_pacientes['presion_sistolica'] > 140) |
>    (df_pacientes['colesterol'] > 240)
> ]
> ```
> 
> ### ðŸ“Š **Finanzas**
> 
> ```python
> # AnÃ¡lisis de riesgo crediticio
> clientes_alto_riesgo = df_creditos[
>    (df_creditos['ingresos'] < 30000) &
>    (df_creditos['deuda_actual'] > df_creditos['ingresos'] * 0.4)
> ]
> ```
> 
> ### ðŸŽ“ **EducaciÃ³n**
> 
> ```python
> # AnÃ¡lisis de rendimiento acadÃ©mico
> estudiantes_en_riesgo = df_estudiantes[
>    (df_estudiantes['promedio'] < 7.0) &
>    (df_estudiantes['asistencia'] < 0.8)
> ]
> ```

## ðŸ”§ Consejos y Mejores PrÃ¡cticas

> [!warning]- **âš ï¸ Errores Comunes y CÃ³mo Evitarlos**
> 
> ### ðŸš¨ **Top 5 Errores de Principiantes**
> 
> |Error|Problema|SoluciÃ³n|CÃ³digo|
> |---|---|---|---|
> |**ðŸ”— Chained Indexing**|`df['A'][0] = valor`|Usar .loc|`df.loc[0, 'A'] = valor`|
> |**ðŸ§  Copia vs Vista**|Modificar sin copy()|Usar .copy()|`df_nuevo = df.copy()`|
> |**ðŸ“Š Tipos de Datos**|No verificar dtypes|Siempre revisar|`df.dtypes`|
> |**ðŸ•³ï¸ Valores Nulos**|Ignorar NaN|Manejar explÃ­citamente|`df.fillna()` o `df.dropna()`|
> |**âš¡ Rendimiento**|Loops innecesarios|Usar vectorizaciÃ³n|MÃ©todos de pandas|
> 
> ### âœ… **Mejores PrÃ¡cticas**
> 
> ```python
> # âœ… HACER
> df_limpio = df.copy()  # Trabajar con copias
> df.dtypes  # Verificar tipos de datos
> df.memory_usage(deep=True)  # Monitorear memoria
> 
> # âŒ EVITAR
> for i in range(len(df)):  # Loops lentos
>    df.iloc[i, 0] = valor
> ```

## ðŸš€ Recursos Adicionales

> [!info]- **ðŸ“š Para Profundizar**
> 
> ### ðŸ”— **Enlaces Ãštiles**
> 
> - [DocumentaciÃ³n Oficial de Pandas](https://pandas.pydata.org/docs/)
> - [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)
> - [10 Minutes to Pandas](https://pandas.pydata.org/docs/user_guide/10min.html)
> 
> ### ðŸ“– **Libros Recomendados**
> 
> - "Python for Data Analysis" - Wes McKinney
> - "Hands-On Data Analysis with Pandas" - Stefanie Molin
> - "Data Science from Scratch" - Joel Grus
> 
> ### ðŸŽ¥ **Cursos Online**
> 
> - DataCamp: Pandas Fundamentals
> - Coursera: Data Analysis with Python
> - edX: Introduction to Data Science

## ðŸ Resumen Ejecutivo

> [!abstract]- **ðŸ“‹ Puntos Clave del MÃ³dulo**
> 
> ### ðŸŽ¯ **Conceptos Esenciales Dominados**
> 
> - âœ… **Pandas**: La herramienta fundamental para anÃ¡lisis de datos
> - âœ… **Series**: Arrays 1D con Ã­ndices personalizados
> - âœ… **DataFrame**: Tablas 2D para anÃ¡lisis completo
> - âœ… **I/O Operations**: Lectura/escritura de mÃºltiples formatos
> - âœ… **ExploraciÃ³n**: TÃ©cnicas para conocer tus datos
> - âœ… **SelecciÃ³n**: .loc vs .iloc para acceso preciso
> - âœ… **Filtrado**: Consultas condicionales complejas
> 
> ### ðŸš€ **PrÃ³ximos Pasos**
> 
> 1. **PrÃ¡ctica diaria** con datasets reales
> 2. **Combinar** con visualizaciÃ³n (Matplotlib/Seaborn)
> 3. **Integrar** con Machine Learning (scikit-learn)
> 4. **Explorar** funciones avanzadas (groupby, pivot, merge)

---

#pandas #dataanalysis #python #datastructures #csv #excel #json #dataexploration #filtering #indexing #datascience #programming #fundamentals